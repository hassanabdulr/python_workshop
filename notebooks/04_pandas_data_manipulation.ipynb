{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bf7602",
   "metadata": {},
   "source": [
    "# Part 4: Pandas DataFrames - Data Loading and Manipulation\n",
    "\n",
    "In this notebook, we'll dive deep into Pandas DataFrames, learning how to load data and perform essential data manipulation operations.\n",
    "\n",
    "## Topics Covered:\n",
    "- Loading data from CSV, TSV, and TXT files\n",
    "- Selecting columns and rows\n",
    "- Filtering data\n",
    "- Dropping missing values and columns\n",
    "- Grouping data\n",
    "- Joining/Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11591958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For this workshop, we'll create sample data\n",
    "# In real scenarios, you'd load actual files\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ffcb6",
   "metadata": {},
   "source": [
    "## 1. Loading Data from Files\n",
    "\n",
    "Pandas can read data from various file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9235a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV files (Comma-Separated Values)\n",
    "# df = pd.read_csv('data/file.csv')\n",
    "\n",
    "# Loading TSV files (Tab-Separated Values)\n",
    "# df = pd.read_csv('data/file.tsv', sep='\\t')\n",
    "\n",
    "# Loading TXT files with custom delimiter\n",
    "# df = pd.read_csv('data/file.txt', delimiter='|')\n",
    "\n",
    "# Common parameters:\n",
    "# - header: row number to use as column names (default: 0)\n",
    "# - index_col: column to use as row labels\n",
    "# - usecols: list of columns to read\n",
    "# - na_values: values to recognize as NA/NaN\n",
    "\n",
    "# For this workshop, let's create a sample dataset\n",
    "np.random.seed(42)\n",
    "sales_data = {\n",
    "    'date': pd.date_range('2024-01-01', periods=100),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Monitor'], 100),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'sales': np.random.randint(1000, 10000, 100),\n",
    "    'quantity': np.random.randint(1, 20, 100),\n",
    "    'customer_rating': np.random.choice([4.0, 4.5, 5.0, np.nan], 100)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sales_data)\n",
    "print(\"Sample sales data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69dad3",
   "metadata": {},
   "source": [
    "## 2. Selecting Columns and Rows\n",
    "\n",
    "There are multiple ways to select data from a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column (returns a Series)\n",
    "products = df['product']\n",
    "print(\"Product column (Series):\")\n",
    "print(products.head())\n",
    "\n",
    "# Select multiple columns (returns a DataFrame)\n",
    "subset = df[['product', 'sales', 'quantity']]\n",
    "print(\"\\nMultiple columns:\")\n",
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by index position with iloc\n",
    "print(\"First row:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.iloc[0:5])\n",
    "\n",
    "print(\"\\nSpecific rows and columns:\")\n",
    "print(df.iloc[0:3, 1:4])  # Rows 0-2, Columns 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by label with loc\n",
    "print(\"Using loc with row indices and column names:\")\n",
    "print(df.loc[0:4, ['product', 'sales']])\n",
    "\n",
    "# Boolean indexing\n",
    "print(\"\\nRows where sales > 8000:\")\n",
    "high_sales = df.loc[df['sales'] > 8000]\n",
    "print(high_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088519a",
   "metadata": {},
   "source": [
    "## 3. Filtering Data\n",
    "\n",
    "Filtering allows you to extract rows based on conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17faed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single condition\n",
    "laptops = df[df['product'] == 'Laptop']\n",
    "print(f\"Laptop sales: {len(laptops)} records\")\n",
    "print(laptops.head())\n",
    "\n",
    "# Multiple conditions with & (and) and | (or)\n",
    "# Note: Use & instead of 'and', | instead of 'or'\n",
    "# Wrap each condition in parentheses\n",
    "\n",
    "high_laptop_sales = df[(df['product'] == 'Laptop') & (df['sales'] > 5000)]\n",
    "print(f\"\\nHigh-value laptop sales: {len(high_laptop_sales)} records\")\n",
    "print(high_laptop_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using isin() for multiple values\n",
    "electronics = df[df['product'].isin(['Laptop', 'Phone'])]\n",
    "print(f\"Laptops and Phones: {len(electronics)} records\")\n",
    "\n",
    "# Using str methods for string filtering\n",
    "# (Example: if we had product names with patterns)\n",
    "# df[df['product'].str.contains('Lap')]\n",
    "# df[df['product'].str.startswith('L')]\n",
    "\n",
    "# Filter by date range\n",
    "january_sales = df[df['date'] < '2024-02-01']\n",
    "print(f\"\\nJanuary sales: {len(january_sales)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6dd9c",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Values\n",
    "\n",
    "Real-world data often has missing values that need to be handled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)\n",
    "\n",
    "# Check which rows have any missing values\n",
    "rows_with_na = df[df.isnull().any(axis=1)]\n",
    "print(f\"\\nRows with missing values: {len(rows_with_na)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df_no_na = df.dropna()\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"After dropping NA: {df_no_na.shape}\")\n",
    "\n",
    "# Drop rows where specific columns have missing values\n",
    "df_rating_clean = df.dropna(subset=['customer_rating'])\n",
    "print(f\"After dropping rows with missing ratings: {df_rating_clean.shape}\")\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df.copy()\n",
    "df_filled['customer_rating'].fillna(df_filled['customer_rating'].mean(), inplace=True)\n",
    "print(f\"\\nMissing values after filling: {df_filled['customer_rating'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425da61",
   "metadata": {},
   "source": [
    "## 5. Dropping Columns\n",
    "\n",
    "Sometimes you need to remove columns from your DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2428a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a single column\n",
    "df_no_rating = df.drop('customer_rating', axis=1)\n",
    "# axis=1 means drop column, axis=0 would drop rows\n",
    "print(\"Columns after dropping customer_rating:\")\n",
    "print(df_no_rating.columns.tolist())\n",
    "\n",
    "# Drop multiple columns\n",
    "df_minimal = df.drop(['customer_rating', 'quantity'], axis=1)\n",
    "print(\"\\nColumns after dropping multiple:\")\n",
    "print(df_minimal.columns.tolist())\n",
    "\n",
    "# Note: Original df is unchanged unless you use inplace=True\n",
    "# df.drop('column', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c99f6b",
   "metadata": {},
   "source": [
    "## 6. Grouping Data\n",
    "\n",
    "Group by allows you to aggregate data based on categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by a single column\n",
    "product_summary = df.groupby('product')['sales'].sum()\n",
    "print(\"Total sales by product:\")\n",
    "print(product_summary)\n",
    "\n",
    "# Multiple aggregations\n",
    "product_stats = df.groupby('product')['sales'].agg(['sum', 'mean', 'count'])\n",
    "print(\"\\nProduct statistics:\")\n",
    "print(product_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e131d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "region_product = df.groupby(['region', 'product'])['sales'].sum()\n",
    "print(\"Sales by region and product:\")\n",
    "print(region_product)\n",
    "\n",
    "# Unstack for better readability\n",
    "print(\"\\nUnstacked view:\")\n",
    "print(region_product.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation functions\n",
    "custom_agg = df.groupby('region').agg({\n",
    "    'sales': ['sum', 'mean'],\n",
    "    'quantity': 'sum',\n",
    "    'customer_rating': 'mean'\n",
    "})\n",
    "\n",
    "print(\"Custom aggregation:\")\n",
    "print(custom_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d67eda",
   "metadata": {},
   "source": [
    "## 7. Joining DataFrames\n",
    "\n",
    "Combining data from multiple DataFrames is a common operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79306753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames for demonstration\n",
    "products_df = pd.DataFrame({\n",
    "    'product_id': [1, 2, 3, 4],\n",
    "    'product_name': ['Laptop', 'Phone', 'Tablet', 'Monitor'],\n",
    "    'category': ['Computer', 'Mobile', 'Mobile', 'Computer']\n",
    "})\n",
    "\n",
    "prices_df = pd.DataFrame({\n",
    "    'product_id': [1, 2, 3, 5],\n",
    "    'price': [1200, 800, 500, 300],\n",
    "    'currency': ['USD', 'USD', 'USD', 'USD']\n",
    "})\n",
    "\n",
    "print(\"Products:\")\n",
    "print(products_df)\n",
    "print(\"\\nPrices:\")\n",
    "print(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN - only matching rows from both DataFrames\n",
    "inner_join = pd.merge(products_df, prices_df, on='product_id', how='inner')\n",
    "print(\"Inner Join (only matching):\")\n",
    "print(inner_join)\n",
    "print(f\"Shape: {inner_join.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN - all rows from left DataFrame, matching from right\n",
    "left_join = pd.merge(products_df, prices_df, on='product_id', how='left')\n",
    "print(\"Left Join (all products):\")\n",
    "print(left_join)\n",
    "print(f\"Shape: {left_join.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIGHT JOIN - all rows from right DataFrame, matching from left\n",
    "right_join = pd.merge(products_df, prices_df, on='product_id', how='right')\n",
    "print(\"Right Join (all prices):\")\n",
    "print(right_join)\n",
    "print(f\"Shape: {right_join.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTER JOIN - all rows from both DataFrames\n",
    "outer_join = pd.merge(products_df, prices_df, on='product_id', how='outer')\n",
    "print(\"Outer Join (all rows):\")\n",
    "print(outer_join)\n",
    "print(f\"Shape: {outer_join.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9570336",
   "metadata": {},
   "source": [
    "## 8. Practical Example: Complete Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c192eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical scenario: Analyzing sales data\n",
    "\n",
    "# 1. Load data (in real scenario)\n",
    "# df = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# 2. Inspect data\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# 3. Handle missing values\n",
    "df_clean = df.dropna(subset=['sales', 'quantity'])\n",
    "df_clean['customer_rating'].fillna(df_clean['customer_rating'].mean(), inplace=True)\n",
    "\n",
    "# 4. Filter for specific criteria\n",
    "high_value = df_clean[df_clean['sales'] > 5000]\n",
    "\n",
    "# 5. Group and aggregate\n",
    "summary = high_value.groupby(['region', 'product']).agg({\n",
    "    'sales': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'customer_rating': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nHigh-value sales summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19907ded",
   "metadata": {},
   "source": [
    "## Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: From the original df, filter for:\n",
    "# - Product is 'Phone' or 'Tablet'\n",
    "# - Sales greater than 3000\n",
    "# - Region is 'North' or 'South'\n",
    "# Print the shape and first 5 rows\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4425104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a summary showing:\n",
    "# - Average sales per product\n",
    "# - Total quantity sold per product\n",
    "# - Count of transactions per product\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create two DataFrames and join them\n",
    "# df1: product_id, product_name\n",
    "# df2: product_id, stock_level\n",
    "# Perform an inner join\n",
    "\n",
    "# Your code here:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
