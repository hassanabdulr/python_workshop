{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bf7602",
   "metadata": {},
   "source": [
    "# Part 4: Pandas DataFrames - Data Loading and Manipulation\n",
    "\n",
    "In this notebook, we'll dive deep into Pandas DataFrames, learning how to load data and perform essential data manipulation operations.\n",
    "\n",
    "## Topics Covered:\n",
    "- Loading data from CSV, TSV, and TXT files\n",
    "- Selecting columns and rows\n",
    "- Filtering data\n",
    "- Dropping missing values and columns\n",
    "- Grouping data\n",
    "- Joining/Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11591958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For this workshop, we'll create sample data\n",
    "# In real scenarios, you'd load actual files\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ffcb6",
   "metadata": {},
   "source": [
    "## 1. Loading Data from Files\n",
    "\n",
    "Pandas can read data from various file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9235a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loading CSV files (Comma-Separated Values)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m demo_df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/demo_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDemographic data loaded from CSV:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(demo_df.head())\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading CSV files (Comma-Separated Values)\n",
    "demo_df = pd.read_csv('../data/demo_data.csv')\n",
    "print(\"Demographic data loaded from CSV:\")\n",
    "print(demo_df.head())\n",
    "print(f\"\\nShape: {demo_df.shape}\")\n",
    "\n",
    "# Loading TSV files (Tab-Separated Values)\n",
    "demo_tsv = pd.read_csv('../data/demo_data.tsv', sep='\\t')\n",
    "print(\"\\n\\nSame data loaded from TSV:\")\n",
    "print(demo_tsv.head(3))\n",
    "\n",
    "# Loading TXT files with custom delimiter\n",
    "demo_txt = pd.read_csv('../data/demo_data.txt', sep=' ')\n",
    "print(\"\\n\\nSame data loaded from TXT (space-delimited):\")\n",
    "print(demo_txt.head(3))\n",
    "\n",
    "# Common parameters:\n",
    "# - header: row number to use as column names (default: 0)\n",
    "# - index_col: column to use as row labels\n",
    "# - usecols: list of columns to read\n",
    "# - na_values: values to recognize as NA/NaN\n",
    "\n",
    "print(\"\\n\\nAll three methods load the same data!\")\n",
    "print(f\"CSV shape: {demo_df.shape}, TSV shape: {demo_tsv.shape}, TXT shape: {demo_txt.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260fd778",
   "metadata": {},
   "source": [
    "## 2. Loading Multiple Related Datasets\n",
    "\n",
    "In research, data is often split across multiple files. Let's load all our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "demo_df = pd.read_csv('../data/demo_data.csv')\n",
    "neuropsych_df = pd.read_csv('../data/neuropsych_data.csv')\n",
    "imaging_df = pd.read_csv('../data/imaging_data.csv')\n",
    "biomarker_df = pd.read_csv('../data/biomarker_data.csv')\n",
    "clinical_df = pd.read_csv('../data/clinical_data.csv')\n",
    "\n",
    "print(\"Demographic data:\")\n",
    "print(demo_df.head())\n",
    "print(f\"Shape: {demo_df.shape}\\n\")\n",
    "\n",
    "print(\"Neuropsychological data:\")\n",
    "print(neuropsych_df.head())\n",
    "print(f\"Shape: {neuropsych_df.shape}\\n\")\n",
    "\n",
    "print(\"Imaging data (note: only half of participants have imaging):\")\n",
    "print(imaging_df.head())\n",
    "print(f\"Shape: {imaging_df.shape}\\n\")\n",
    "\n",
    "print(\"Biomarker data:\")\n",
    "print(biomarker_df.head())\n",
    "print(f\"Shape: {biomarker_df.shape}\\n\")\n",
    "\n",
    "print(\"Clinical data:\")\n",
    "print(clinical_df.head())\n",
    "print(f\"Shape: {clinical_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69dad3",
   "metadata": {},
   "source": [
    "## 3. Selecting Columns and Rows\n",
    "\n",
    "There are multiple ways to select data from a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column (returns a Series)\n",
    "ages = demo_df['age']\n",
    "print(\"Age column (Series):\")\n",
    "print(ages.head())\n",
    "print(f\"\\nType: {type(ages)}\")\n",
    "\n",
    "# Select multiple columns (returns a DataFrame)\n",
    "subset = demo_df[['record_id', 'age', 'sex']]\n",
    "print(\"\\n\\nMultiple columns:\")\n",
    "print(subset.head())\n",
    "print(f\"Type: {type(subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by index position with iloc\n",
    "print(\"First row:\")\n",
    "print(demo_df.iloc[0])\n",
    "\n",
    "print(\"\\n\\nFirst 5 rows:\")\n",
    "print(demo_df.iloc[0:5])\n",
    "\n",
    "print(\"\\n\\nSpecific rows and columns:\")\n",
    "print(demo_df.iloc[0:3, 1:4])  # Rows 0-2, Columns 1-3 (age, sex, education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by label with loc\n",
    "print(\"Using loc with row indices and column names:\")\n",
    "print(demo_df.loc[0:4, ['record_id', 'age', 'education_level']])\n",
    "\n",
    "# Boolean indexing - more powerful for filtering\n",
    "print(\"\\n\\nRows where age > 70:\")\n",
    "elderly = demo_df.loc[demo_df['age'] > 70]\n",
    "print(elderly.head())\n",
    "print(f\"Number of elderly participants: {len(elderly)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088519a",
   "metadata": {},
   "source": [
    "## 4. Filtering Data\n",
    "\n",
    "Filtering allows you to extract rows based on conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17faed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single condition - filter by education level\n",
    "phd_participants = demo_df[demo_df['education_level'] == 'phd']\n",
    "print(f\"PhD participants: {len(phd_participants)} records\")\n",
    "print(phd_participants.head())\n",
    "\n",
    "# Multiple conditions with & (and) and | (or)\n",
    "# Note: Use & instead of 'and', | instead of 'or'\n",
    "# Wrap each condition in parentheses\n",
    "\n",
    "# Young females with bachelor's degree or higher\n",
    "young_educated_females = demo_df[\n",
    "    (demo_df['age'] < 30) & \n",
    "    (demo_df['sex'] == 'F') & \n",
    "    (demo_df['education_level'].isin(['bachelor', 'master', 'phd']))\n",
    "]\n",
    "print(f\"\\n\\nYoung educated females: {len(young_educated_females)} records\")\n",
    "print(young_educated_females.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using isin() for multiple values\n",
    "bachelor_or_master = demo_df[demo_df['education_level'].isin(['bachelor', 'master'])]\n",
    "print(f\"Participants with bachelor or master: {len(bachelor_or_master)} records\")\n",
    "print(f\"Breakdown by education:\")\n",
    "print(bachelor_or_master['education_level'].value_counts())\n",
    "\n",
    "# Filter the clinical data by health conditions\n",
    "print(\"\\n\\nClinical data filtering:\")\n",
    "# Participants with diabetes\n",
    "diabetes_patients = clinical_df[clinical_df['diabetes'] == 1]\n",
    "print(f\"Participants with diabetes: {len(diabetes_patients)}\")\n",
    "\n",
    "# Participants with high cholesterol (>240 mg/dL)\n",
    "high_cholesterol = clinical_df[clinical_df['cholesterol_mg_dl'] > 240]\n",
    "print(f\"Participants with high cholesterol: {len(high_cholesterol)}\")\n",
    "\n",
    "# Participants with MCI (Mild Cognitive Impairment)\n",
    "mci_patients = clinical_df[clinical_df['mild_cognitive_impairment'] == 1]\n",
    "print(f\"Participants with MCI: {len(mci_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6dd9c",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values\n",
    "\n",
    "Real-world data often has missing values that need to be handled. \n",
    "Note: Our imaging and biomarker data only have measurements for half the participants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's merge some datasets to create missing values\n",
    "# Merge demographic data with imaging data (left join - keeps all demographics)\n",
    "demo_with_imaging = demo_df.merge(imaging_df, on='record_id', how='left')\n",
    "\n",
    "print(\"After merging demographics with imaging:\")\n",
    "print(demo_with_imaging.head(10))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n\\nMissing values per column:\")\n",
    "print(demo_with_imaging.isnull().sum())\n",
    "\n",
    "print(\"\\n\\nPercentage of missing values:\")\n",
    "print((demo_with_imaging.isnull().sum() / len(demo_with_imaging)) * 100)\n",
    "\n",
    "# Check which rows have any missing values\n",
    "rows_with_na = demo_with_imaging[demo_with_imaging.isnull().any(axis=1)]\n",
    "print(f\"\\n\\nRows with missing values: {len(rows_with_na)}\")\n",
    "print(rows_with_na.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df_no_na = demo_with_imaging.dropna()\n",
    "print(f\"Original shape: {demo_with_imaging.shape}\")\n",
    "print(f\"After dropping NA: {df_no_na.shape}\")\n",
    "print(f\"Lost {demo_with_imaging.shape[0] - df_no_na.shape[0]} rows\")\n",
    "\n",
    "# Drop rows where specific columns have missing values\n",
    "# Only drop if imaging data is missing\n",
    "df_imaging_only = demo_with_imaging.dropna(subset=['hippocampus_volume', 'amygdala_volume'])\n",
    "print(f\"\\nAfter dropping rows with missing imaging: {df_imaging_only.shape}\")\n",
    "\n",
    "# Fill missing values with mean (common strategy for numerical data)\n",
    "df_filled = demo_with_imaging.copy()\n",
    "print(f\"\\n\\nBefore filling - missing hippocampus volumes: {df_filled['hippocampus_volume'].isnull().sum()}\")\n",
    "\n",
    "df_filled['hippocampus_volume'].fillna(df_filled['hippocampus_volume'].mean(), inplace=True)\n",
    "df_filled['amygdala_volume'].fillna(df_filled['amygdala_volume'].mean(), inplace=True)\n",
    "df_filled['cortical_thickness'].fillna(df_filled['cortical_thickness'].mean(), inplace=True)\n",
    "\n",
    "print(f\"After filling - missing hippocampus volumes: {df_filled['hippocampus_volume'].isnull().sum()}\")\n",
    "\n",
    "# Alternative: Fill with median or a specific value\n",
    "# df['column'].fillna(df['column'].median(), inplace=True)\n",
    "# df['column'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425da61",
   "metadata": {},
   "source": [
    "## 6. Dropping Columns\n",
    "\n",
    "Sometimes you need to remove columns from your DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2428a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a single column\n",
    "clinical_subset = clinical_df.drop('smoking_status', axis=1)\n",
    "# axis=1 means drop column, axis=0 would drop rows\n",
    "print(\"Original columns:\")\n",
    "print(clinical_df.columns.tolist())\n",
    "print(\"\\nColumns after dropping smoking_status:\")\n",
    "print(clinical_subset.columns.tolist())\n",
    "\n",
    "# Drop multiple columns\n",
    "neuropsych_minimal = neuropsych_df.drop(['attention_score', 'executive_function_score'], axis=1)\n",
    "print(\"\\n\\nNeuropsych columns after dropping:\")\n",
    "print(neuropsych_minimal.columns.tolist())\n",
    "print(neuropsych_minimal.head())\n",
    "\n",
    "# Note: Original df is unchanged unless you use inplace=True\n",
    "print(f\"\\n\\nOriginal neuropsych_df still has {neuropsych_df.shape[1]} columns\")\n",
    "# To modify the original: neuropsych_df.drop('column', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c99f6b",
   "metadata": {},
   "source": [
    "## 7. Grouping Data\n",
    "\n",
    "Group by allows you to aggregate data based on categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by a single column - average age by education level\n",
    "age_by_education = demo_df.groupby('education_level')['age'].mean()\n",
    "print(\"Average age by education level:\")\n",
    "print(age_by_education)\n",
    "\n",
    "# Multiple aggregations\n",
    "education_stats = demo_df.groupby('education_level')['age'].agg(['mean', 'median', 'std', 'count'])\n",
    "print(\"\\n\\nAge statistics by education level:\")\n",
    "print(education_stats.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e131d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns - count participants by sex and education\n",
    "sex_edu_counts = demo_df.groupby(['sex', 'education_level']).size()\n",
    "print(\"Participant counts by sex and education:\")\n",
    "print(sex_edu_counts)\n",
    "\n",
    "# Unstack for better readability (create a pivot table)\n",
    "print(\"\\n\\nUnstacked view (crosstab format):\")\n",
    "print(sex_edu_counts.unstack())\n",
    "\n",
    "# Alternative: use value_counts with multiple columns\n",
    "print(\"\\n\\nUsing value_counts:\")\n",
    "print(demo_df.value_counts(['sex', 'education_level']).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation functions on clinical data\n",
    "# Group by diabetes status and get various health metrics\n",
    "clinical_by_diabetes = clinical_df.groupby('diabetes').agg({\n",
    "    'cholesterol_mg_dl': ['mean', 'std'],\n",
    "    'systolic_bp_mm_hg': ['mean', 'std'],\n",
    "    'bmi': ['mean', 'std'],\n",
    "    'mild_cognitive_impairment': 'sum'  # Count how many have MCI in each group\n",
    "})\n",
    "\n",
    "print(\"Health metrics by diabetes status:\")\n",
    "print(clinical_by_diabetes.round(2))\n",
    "\n",
    "# Group by smoking status\n",
    "print(\"\\n\\nHealth metrics by smoking status:\")\n",
    "smoking_stats = clinical_df.groupby('smoking_status').agg({\n",
    "    'cholesterol_mg_dl': 'mean',\n",
    "    'systolic_bp_mm_hg': 'mean',\n",
    "    'bmi': 'mean',\n",
    "    'diabetes': 'sum'\n",
    "}).round(2)\n",
    "print(smoking_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d67eda",
   "metadata": {},
   "source": [
    "## 8. Joining DataFrames\n",
    "\n",
    "Combining data from multiple DataFrames is essential for research data analysis.\n",
    "Let's explore all four types of joins with our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79306753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's understand our data before joining\n",
    "print(\"Dataset sizes:\")\n",
    "print(f\"Demographics: {demo_df.shape[0]} participants\")\n",
    "print(f\"Neuropsych: {neuropsych_df.shape[0]} participants\")\n",
    "print(f\"Imaging: {imaging_df.shape[0]} participants\")\n",
    "print(f\"Biomarker: {biomarker_df.shape[0]} participants\")\n",
    "print(f\"Clinical: {clinical_df.shape[0]} participants\")\n",
    "\n",
    "print(\"\\n\\nFirst few record_ids from each dataset:\")\n",
    "print(\"Demo:\", demo_df['record_id'].head(3).tolist())\n",
    "print(\"Imaging:\", imaging_df['record_id'].head(3).tolist())\n",
    "print(\"Biomarker:\", biomarker_df['record_id'].head(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN - only participants who have BOTH demographic AND imaging data\n",
    "# This keeps only the 500 participants who have imaging scans\n",
    "inner_join = pd.merge(demo_df, imaging_df, on='record_id', how='inner')\n",
    "print(\"Inner Join (participants with both demo AND imaging):\")\n",
    "print(f\"Shape: {inner_join.shape}\")\n",
    "print(inner_join.head())\n",
    "print(f\"\\n{len(inner_join)} participants have complete data in both datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN - keep ALL demographic data, add imaging where available\n",
    "# This is most common in research - keep all participants, add measurements where available\n",
    "left_join = pd.merge(demo_df, imaging_df, on='record_id', how='left')\n",
    "print(\"Left Join (all demographics, imaging where available):\")\n",
    "print(f\"Shape: {left_join.shape}\")\n",
    "print(left_join.head(10))\n",
    "\n",
    "# Check for missing values (participants without imaging)\n",
    "print(f\"\\nParticipants without imaging data: {left_join['hippocampus_volume'].isnull().sum()}\")\n",
    "print(f\"Participants with imaging data: {left_join['hippocampus_volume'].notnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIGHT JOIN - keep ALL imaging data, add demographics where available\n",
    "# In this case, same as inner join since all imaging participants have demographics\n",
    "right_join = pd.merge(demo_df, imaging_df, on='record_id', how='right')\n",
    "print(\"Right Join (all imaging, demographics where available):\")\n",
    "print(f\"Shape: {right_join.shape}\")\n",
    "print(right_join.head())\n",
    "\n",
    "# Since all imaging participants also have demographics, no missing values\n",
    "print(f\"\\nMissing demographic data: {right_join['age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTER JOIN - keep ALL rows from both DataFrames\n",
    "# In this case, same as left join since imaging is a subset of demographics\n",
    "outer_join = pd.merge(demo_df, imaging_df, on='record_id', how='outer')\n",
    "print(\"Outer Join (all rows from both datasets):\")\n",
    "print(f\"Shape: {outer_join.shape}\")\n",
    "print(outer_join.head(10))\n",
    "\n",
    "print(f\"\\nTotal participants: {len(outer_join)}\")\n",
    "print(f\"With imaging: {outer_join['hippocampus_volume'].notnull().sum()}\")\n",
    "print(f\"Without imaging: {outer_join['hippocampus_volume'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6685fd",
   "metadata": {},
   "source": [
    "### Joining Multiple DataFrames\n",
    "\n",
    "In research, we often need to combine many datasets. Let's merge everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets together - chain multiple merges\n",
    "# Start with demographics, then add each dataset using left joins\n",
    "complete_data = demo_df \\\n",
    "    .merge(neuropsych_df, on='record_id', how='left') \\\n",
    "    .merge(imaging_df, on='record_id', how='left') \\\n",
    "    .merge(biomarker_df, on='record_id', how='left') \\\n",
    "    .merge(clinical_df, on='record_id', how='left')\n",
    "\n",
    "print(\"Complete merged dataset:\")\n",
    "print(f\"Shape: {complete_data.shape}\")\n",
    "print(f\"Columns: {complete_data.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\\nFirst few rows:\")\n",
    "print(complete_data.head())\n",
    "\n",
    "print(\"\\n\\nMissing value summary:\")\n",
    "print(complete_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9570336",
   "metadata": {},
   "source": [
    "## 9. Practical Example: Complete Data Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c192eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world research scenario: Analyzing cognitive health\n",
    "\n",
    "# 1. Load all data\n",
    "demo = pd.read_csv('../data/demo_data.csv')\n",
    "neuropsych = pd.read_csv('../data/neuropsych_data.csv')\n",
    "imaging = pd.read_csv('../data/imaging_data.csv')\n",
    "clinical = pd.read_csv('../data/clinical_data.csv')\n",
    "\n",
    "print(\"Step 1: Data loaded\")\n",
    "print(f\"Demographics: {demo.shape}, Neuropsych: {neuropsych.shape}\")\n",
    "print(f\"Imaging: {imaging.shape}, Clinical: {clinical.shape}\")\n",
    "\n",
    "# 2. Merge datasets (left join to keep all participants)\n",
    "analysis_df = demo \\\n",
    "    .merge(neuropsych, on='record_id', how='left') \\\n",
    "    .merge(imaging, on='record_id', how='left') \\\n",
    "    .merge(clinical, on='record_id', how='left')\n",
    "\n",
    "print(f\"\\nStep 2: Merged data shape: {analysis_df.shape}\")\n",
    "\n",
    "# 3. Filter for complete cases (participants with all measurements)\n",
    "complete_cases = analysis_df.dropna()\n",
    "print(f\"\\nStep 3: Complete cases: {complete_cases.shape[0]} participants\")\n",
    "\n",
    "# 4. Filter for specific research criteria\n",
    "# Example: Adults 40-70, with complete imaging and neuropsych data\n",
    "study_sample = complete_cases[\n",
    "    (complete_cases['age'] >= 40) & \n",
    "    (complete_cases['age'] <= 70)\n",
    "]\n",
    "print(f\"\\nStep 4: Study sample (age 40-70): {study_sample.shape[0]} participants\")\n",
    "\n",
    "# 5. Group and analyze by key variables\n",
    "print(\"\\n\\nStep 5: Analysis Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cognitive scores by MCI status\n",
    "print(\"\\nMemory scores by MCI status:\")\n",
    "mci_memory = study_sample.groupby('mild_cognitive_impairment')['memory_score'].agg(['mean', 'std', 'count'])\n",
    "print(mci_memory.round(2))\n",
    "\n",
    "# Brain volumes by sex\n",
    "print(\"\\n\\nHippocampus volume by sex:\")\n",
    "hip_by_sex = study_sample.groupby('sex')['hippocampus_volume'].agg(['mean', 'std', 'count'])\n",
    "print(hip_by_sex.round(2))\n",
    "\n",
    "# Health metrics by education level\n",
    "print(\"\\n\\nCholesterol by education level:\")\n",
    "chol_by_edu = study_sample.groupby('education_level')['cholesterol_mg_dl'].agg(['mean', 'std', 'count'])\n",
    "print(chol_by_edu.round(2))\n",
    "\n",
    "# 6. Create summary statistics for paper\n",
    "print(\"\\n\\nStep 6: Sample Characteristics Table\")\n",
    "print(\"=\"*60)\n",
    "summary_stats = study_sample[['age', 'memory_score', 'hippocampus_volume', 'cholesterol_mg_dl', 'bmi']].describe()\n",
    "print(summary_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19907ded",
   "metadata": {},
   "source": [
    "## 10. Practice Exercises\n",
    "\n",
    "Now it's your turn! Use the datasets we've loaded to practice your skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: From the clinical_df, filter for participants who:\n",
    "# - Have diabetes (diabetes == 1)\n",
    "# - Are current smokers\n",
    "# - Have BMI > 30\n",
    "# Print the shape and first 10 rows\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4425104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Using the neuropsych_df, create a summary showing:\n",
    "# - Mean of all three cognitive scores\n",
    "# - Standard deviation of all three scores\n",
    "# - Minimum and maximum values\n",
    "# Hint: Use .agg() with a list of functions\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Merge demo_df with clinical_df\n",
    "# Then group by education_level and calculate:\n",
    "# - Average cholesterol\n",
    "# - Average BMI\n",
    "# - Count of participants with diabetes (sum the diabetes column)\n",
    "# Print the results sorted by education level\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 (Bonus): Create a complete dataset by merging all 5 dataframes\n",
    "# Then filter for participants who:\n",
    "# - Are female\n",
    "# - Have master's or PhD education\n",
    "# - Have imaging data (hippocampus_volume is not null)\n",
    "# - Have memory_score > 100\n",
    "# Calculate the average hippocampus_volume for this group\n",
    "\n",
    "# Your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
